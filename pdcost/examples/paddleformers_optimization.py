#!/usr/bin/env python3
"""
PaddleFormers æ¡†æ¶ä¼˜åŒ–æœºåˆ¶æ¼”ç¤º

æœ¬ç¤ºä¾‹å±•ç¤º PaddleFormers ç‰¹æœ‰çš„ä¼˜åŒ–æœºåˆ¶å¯¹æ˜¾å­˜é¢„æµ‹çš„å½±å“:
1. ShardingV2 (split_param=True): Stage1 ä¹Ÿåˆ†ç‰‡å‚æ•°å’Œæ¢¯åº¦
2. sd_release_grads: æ¯æ¬¡è¿­ä»£åé‡Šæ”¾æ¢¯åº¦
3. tensorwise_offload_optimizer: ä¼˜åŒ–å™¨çŠ¶æ€åŠ¨æ€ offload åˆ° CPU
"""

from pdcost import PDCostModel, ModelConfig, ParallelConfig, TrainingConfig, HardwareConfig, GPUSpec


def main():
    print("=" * 80)
    print("ğŸš€ PaddleFormers æ¡†æ¶ä¼˜åŒ–æœºåˆ¶æ¼”ç¤º")
    print("=" * 80)
    
    # åˆ›å»º Qwen3-30B-A3B é…ç½®
    model_config = ModelConfig.from_name("qwen3-30b-a3b")
    
    # H800 ç¡¬ä»¶é…ç½®
    hardware = HardwareConfig(
        gpu=GPUSpec(
            name="NVIDIA H800",
            memory_gb=79.6,
            bf16_tflops=788.0,
            fp16_tflops=763.0,
            fp32_tflops=51.6,
            memory_bandwidth_gbps=2780.0
        ),
        num_nodes=1,
        gpus_per_node=8
    )
    
    # è®­ç»ƒé…ç½®
    training = TrainingConfig(
        micro_batch_size=1,
        sequence_length=2048,
        gradient_accumulation_steps=16,
        dtype="bfloat16",
        recompute_granularity="full",
        recompute_method="uniform",
        recompute_num_layers=1,
    )
    
    costmodel = PDCostModel(model_config, hardware, training)
    
    # å¹¶è¡Œé…ç½®: TP1, PP1, DP8, EP8, Stage1
    parallel = ParallelConfig(tp=1, pp=1, dp=8, ep=8, sharding="stage1")
    
    print(f"\nğŸ“‹ æµ‹è¯•é…ç½®:")
    print(f"  æ¨¡å‹: Qwen3-30B-A3B (128 experts, top-8)")
    print(f"  ç¡¬ä»¶: å•æœº 8 Ã— H800 (79.6GB)")
    print(f"  å¹¶è¡Œ: {parallel}")
    print(f"  micro_batch_size: 1, seq_len: 2048")
    
    print("\n" + "=" * 80)
    print("ğŸ“Š PaddleFormers ä¼˜åŒ–æœºåˆ¶å¯¹æ¯”")
    print("=" * 80)
    
    # ========== æ–¹æ¡ˆå¯¹æ¯” ==========
    
    # æ–¹æ¡ˆ 1: ä¼ ç»Ÿ Stage1 (split_param=False)
    result1 = costmodel.predict(parallel, split_param=False, sd_release_grads=False)
    
    # æ–¹æ¡ˆ 2: ShardingV2 é»˜è®¤ (split_param=True)
    result2 = costmodel.predict(parallel, split_param=True, sd_release_grads=False)
    
    # æ–¹æ¡ˆ 3: ShardingV2 + sd_release_grads
    result3 = costmodel.predict(parallel, split_param=True, sd_release_grads=True)
    
    # æ–¹æ¡ˆ 4: å…¨ä¼˜åŒ– (ShardingV2 + release_grads + offload)
    result4 = costmodel.predict(
        parallel, 
        split_param=True, 
        sd_release_grads=True,
        tensorwise_offload_optimizer=True,
        tensorwise_offload_ratio=0.95
    )
    
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    print(f"\n{'æ–¹æ¡ˆ':<45} {'å‚æ•°':<10} {'æ¢¯åº¦':<10} {'ä¼˜åŒ–å™¨':<10} {'æ€»æ˜¾å­˜':<10} {'çŠ¶æ€':<6}")
    print("-" * 100)
    
    results = [
        ("1. ä¼ ç»Ÿ Stage1 (split_param=False)", result1),
        ("2. ShardingV2 (split_param=True)", result2),
        ("3. ShardingV2 + sd_release_grads", result3),
        ("4. ShardingV2 + release_grads + offload", result4),
    ]
    
    for name, r in results:
        status = "âœ…" if r.memory_gb <= 79.6 else "âŒ"
        print(f"{name:<45} "
              f"{r.memory_breakdown.parameter_memory_gb:<10.2f} "
              f"{r.memory_breakdown.gradient_memory_gb:<10.2f} "
              f"{r.memory_breakdown.optimizer_memory_gb:<10.2f} "
              f"{r.memory_gb:<10.2f} "
              f"{status:<6}")
    
    print("-" * 100)
    print(f"H800 æ˜¾å­˜é™åˆ¶: 79.6 GB")
    
    # ========== ä¼˜åŒ–æ•ˆæœåˆ†æ ==========
    print("\n" + "=" * 80)
    print("ğŸ“ˆ ä¼˜åŒ–æ•ˆæœåˆ†æ")
    print("=" * 80)
    
    print(f"\n1. ShardingV2 (split_param=True) æ•ˆæœ:")
    param_reduction = (result1.memory_breakdown.parameter_memory_gb - 
                       result2.memory_breakdown.parameter_memory_gb)
    grad_reduction = (result1.memory_breakdown.gradient_memory_gb - 
                      result2.memory_breakdown.gradient_memory_gb)
    print(f"   å‚æ•°æ˜¾å­˜å‡å°‘: {param_reduction:.2f} GB ({param_reduction/result1.memory_breakdown.parameter_memory_gb*100:.1f}%)")
    print(f"   æ¢¯åº¦æ˜¾å­˜å‡å°‘: {grad_reduction:.2f} GB ({grad_reduction/result1.memory_breakdown.gradient_memory_gb*100:.1f}%)")
    print(f"   åŸç†: Stage1 + split_param ä¼šåˆ†ç‰‡å‚æ•°å’Œæ¢¯åº¦ (ç±»ä¼¼ Stage3 æ•ˆæœ)")
    
    print(f"\n2. sd_release_grads æ•ˆæœ:")
    grad_reduction2 = (result2.memory_breakdown.gradient_memory_gb - 
                       result3.memory_breakdown.gradient_memory_gb)
    print(f"   æ¢¯åº¦æ˜¾å­˜å‡å°‘: {grad_reduction2:.2f} GB ({grad_reduction2/result2.memory_breakdown.gradient_memory_gb*100:.1f}%)")
    print(f"   åŸç†: æ¯æ¬¡è¿­ä»£åé‡Šæ”¾æ¢¯åº¦ï¼Œå³°å€¼æ˜¾å­˜ = max(æ¿€æ´», æ¢¯åº¦) è€Œéä¸¤è€…ä¹‹å’Œ")
    
    print(f"\n3. tensorwise_offload_optimizer æ•ˆæœ:")
    opt_reduction = (result3.memory_breakdown.optimizer_memory_gb - 
                     result4.memory_breakdown.optimizer_memory_gb)
    print(f"   ä¼˜åŒ–å™¨æ˜¾å­˜å‡å°‘: {opt_reduction:.2f} GB ({opt_reduction/result3.memory_breakdown.optimizer_memory_gb*100:.1f}%)")
    print(f"   åŸç†: ä¼˜åŒ–å™¨çŠ¶æ€æŒ‰ tensor ç²’åº¦åŠ¨æ€ offload åˆ° CPUï¼Œåªä¿ç•™ 5% åœ¨ GPU")
    
    print(f"\n4. æ€»ä½“ä¼˜åŒ–æ•ˆæœ:")
    total_reduction = result1.memory_gb - result4.memory_gb
    print(f"   æ€»æ˜¾å­˜å‡å°‘: {total_reduction:.2f} GB ({total_reduction/result1.memory_gb*100:.1f}%)")
    print(f"   ä» {result1.memory_gb:.2f} GB é™ä½åˆ° {result4.memory_gb:.2f} GB")
    
    # ========== æ¨èé…ç½® ==========
    print("\n" + "=" * 80)
    print("ğŸ’¡ PaddleFormers è®­ç»ƒæ¨èé…ç½®")
    print("=" * 80)
    
    print("""
å¯¹äº Qwen3-30B-A3B åœ¨å•æœº 8 å¡ H800 ä¸Šè®­ç»ƒ:

1. åŸºç¡€é…ç½® (æ¨è):
   - sharding: stage1
   - split_param: true (é»˜è®¤)
   - é¢„è®¡æ˜¾å­˜: ~54 GB

2. æ˜¾å­˜ä¼˜åŒ–é…ç½®:
   - sharding: stage1
   - split_param: true
   - sd_release_grads: true
   - é¢„è®¡æ˜¾å­˜: ~50 GB

3. æè‡´ä¼˜åŒ–é…ç½® (ç”¨äºæ›´å¤§æ¨¡å‹æˆ–æ›´é•¿åºåˆ—):
   - sharding: stage1
   - split_param: true
   - sd_release_grads: true
   - tensorwise_offload_optimizer: true
   - é¢„è®¡æ˜¾å­˜: ~16 GB

æ³¨æ„: tensorwise_offload_optimizer ä¼šå¢åŠ  CPU-GPU æ•°æ®ä¼ è¾“å¼€é”€ï¼Œ
      å¯èƒ½å½±å“è®­ç»ƒååé‡ï¼Œå»ºè®®ä»…åœ¨æ˜¾å­˜ç´§å¼ æ—¶ä½¿ç”¨ã€‚
""")


if __name__ == "__main__":
    main()