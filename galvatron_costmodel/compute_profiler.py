#!/usr/bin/env python3
"""
ç®—åŠ› Profiler - æµ‹è¯•çœŸå® GPU ç®—åŠ›å¹¶æ‹Ÿåˆç®—åŠ›æ›²çº¿

åŠŸèƒ½ï¼š
1. å¤šç‚¹æµ‹è¯•ä¸åŒè§„æ¨¡ä¸‹çš„æœ‰æ•ˆç®—åŠ› (TFLOPS)
2. æ‹Ÿåˆç®—åŠ›æ›²çº¿ï¼ˆè€ƒè™‘ä¸åŒ GEMM è§„æ¨¡çš„æ•ˆç‡å·®å¼‚ï¼‰
3. æ ¹æ®è®­ç»ƒé…ç½®ä¼°ç®—å¹³å‡æœ‰æ•ˆç®—åŠ›
4. ä¿å­˜/åŠ è½½æµ‹è¯•ç»“æœ
"""

import json
import os
import time
from dataclasses import dataclass, field, asdict
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import numpy as np


@dataclass
class GEMMTestPoint:
    """å•ä¸ª GEMM æµ‹è¯•ç‚¹"""
    m: int
    n: int
    k: int
    time_ms: float
    tflops: float
    efficiency: float  # ç›¸å¯¹äºå³°å€¼çš„æ•ˆç‡


@dataclass
class ComputeProfile:
    """ç®—åŠ›æµ‹è¯• Profile"""
    # ç¡¬ä»¶ä¿¡æ¯
    gpu_name: str = ""
    gpu_count: int = 1
    peak_tflops: float = 989.0  # ç†è®ºå³°å€¼
    
    # æµ‹è¯•ä¿¡æ¯
    test_date: str = ""
    dtype: str = "bfloat16"
    
    # æµ‹è¯•ç»“æœ
    gemm_results: List[Dict] = field(default_factory=list)
    
    # æ‹Ÿåˆå‚æ•°ï¼ˆæ•ˆç‡ vs GEMM è§„æ¨¡ï¼‰
    # efficiency = a * log(flops) + b ï¼ˆå¯¹æ•°æ‹Ÿåˆï¼‰
    fit_a: float = 0.0
    fit_b: float = 0.0
    
    # åˆ†æ®µæ•ˆç‡ï¼ˆæŒ‰ GEMM è§„æ¨¡åˆ†æ®µï¼‰
    efficiency_small: float = 0.3   # M*N*K < 1e9
    efficiency_medium: float = 0.5  # 1e9 <= M*N*K < 1e11
    efficiency_large: float = 0.6   # M*N*K >= 1e11
    
    def get_efficiency(self, m: int, n: int, k: int) -> float:
        """æ ¹æ® GEMM è§„æ¨¡è·å–æ•ˆç‡"""
        flops = 2 * m * n * k
        
        # ä½¿ç”¨æ‹Ÿåˆæ›²çº¿
        if self.fit_a != 0 or self.fit_b != 0:
            log_flops = np.log10(max(flops, 1))
            efficiency = self.fit_a * log_flops + self.fit_b
            return max(0.1, min(0.9, efficiency))
        
        # ä½¿ç”¨åˆ†æ®µæ•ˆç‡
        if flops < 1e9:
            return self.efficiency_small
        elif flops < 1e11:
            return self.efficiency_medium
        else:
            return self.efficiency_large
    
    def get_effective_tflops(self, m: int, n: int, k: int) -> float:
        """è·å–æœ‰æ•ˆç®—åŠ›"""
        return self.peak_tflops * self.get_efficiency(m, n, k)
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict) -> "ComputeProfile":
        """ä»å­—å…¸åˆ›å»º"""
        profile = cls()
        for key, value in data.items():
            if hasattr(profile, key):
                setattr(profile, key, value)
        return profile


class ComputeProfiler:
    """
    ç®—åŠ› Profiler
    
    æµ‹è¯•å¤šä¸ª GEMM è§„æ¨¡ç‚¹ï¼Œæ‹Ÿåˆç®—åŠ›æ›²çº¿
    """
    
    def __init__(self, dtype: str = "bfloat16"):
        self.dtype = dtype
        self.profile: Optional[ComputeProfile] = None
        
        # é»˜è®¤æµ‹è¯•ç‚¹ï¼šè¦†ç›– Transformer å¸¸è§çš„ GEMM è§„æ¨¡
        # (M, N, K) å¯¹åº”ä¸åŒçš„è®¡ç®—åœºæ™¯
        self.default_test_points = [
            # å°è§„æ¨¡ GEMM (Attention çš„å° batch)
            (256, 6144, 6144),      # å° batch attention
            (512, 6144, 6144),
            (1024, 6144, 6144),
            
            # ä¸­ç­‰è§„æ¨¡ GEMM (å…¸å‹çš„ MLP)
            (2048, 6144, 16384),    # MLP up/gate
            (4096, 6144, 16384),
            (8192, 6144, 16384),
            
            # å¤§è§„æ¨¡ GEMM (é•¿åºåˆ—)
            (8192, 16384, 6144),    # MLP down
            (16384, 6144, 6144),    # é•¿åºåˆ— attention
            (32768, 6144, 6144),
            
            # ç‰¹å¤§è§„æ¨¡ GEMM
            (65536, 6144, 6144),
        ]
    
    def run_gemm_test(self, m: int, n: int, k: int,
                      warmup_iters: int = 10,
                      bench_iters: int = 50) -> GEMMTestPoint:
        """
        è¿è¡Œå•ä¸ª GEMM æµ‹è¯•ç‚¹
        """
        import paddle
        
        # åˆ›å»ºæµ‹è¯•çŸ©é˜µ
        dtype_map = {"bfloat16": "bfloat16", "float16": "float16", "float32": "float32"}
        paddle_dtype = dtype_map.get(self.dtype, "bfloat16")
        
        a = paddle.randn([m, k], dtype=paddle_dtype)
        b = paddle.randn([k, n], dtype=paddle_dtype)
        
        # Warmup
        for _ in range(warmup_iters):
            c = paddle.matmul(a, b)
        paddle.device.cuda.synchronize()
        
        # Benchmark
        start = time.perf_counter()
        for _ in range(bench_iters):
            c = paddle.matmul(a, b)
        paddle.device.cuda.synchronize()
        elapsed = time.perf_counter() - start
        
        # è®¡ç®—æŒ‡æ ‡
        time_ms = elapsed / bench_iters * 1000
        flops = 2 * m * n * k * bench_iters
        tflops = flops / elapsed / 1e12
        
        # æ•ˆç‡ï¼ˆéœ€è¦çŸ¥é“å³°å€¼æ‰èƒ½è®¡ç®—ï¼Œå…ˆç”¨é»˜è®¤å€¼ï¼‰
        peak_tflops = 989.0  # H800 BF16
        efficiency = tflops / peak_tflops
        
        return GEMMTestPoint(
            m=m, n=n, k=k,
            time_ms=time_ms,
            tflops=tflops,
            efficiency=efficiency
        )
    
    def run_full_profile(self, 
                         test_points: List[Tuple[int, int, int]] = None,
                         warmup_iters: int = 10,
                         bench_iters: int = 50,
                         peak_tflops: float = 989.0) -> ComputeProfile:
        """
        è¿è¡Œå®Œæ•´çš„ç®—åŠ›æµ‹è¯•
        
        Args:
            test_points: æµ‹è¯•ç‚¹åˆ—è¡¨ [(M, N, K), ...]
            warmup_iters: é¢„çƒ­è¿­ä»£æ¬¡æ•°
            bench_iters: åŸºå‡†æµ‹è¯•è¿­ä»£æ¬¡æ•°
            peak_tflops: GPU ç†è®ºå³°å€¼ç®—åŠ›
        
        Returns:
            ComputeProfile æµ‹è¯•ç»“æœ
        """
        import paddle
        
        if test_points is None:
            test_points = self.default_test_points
        
        # è·å– GPU ä¿¡æ¯
        try:
            gpu_name = paddle.device.cuda.get_device_name(0)
            gpu_count = paddle.device.cuda.device_count()
        except:
            gpu_name = "Unknown GPU"
            gpu_count = 1
        
        print(f"\n{'='*70}")
        print(f"ğŸš€ GPU ç®—åŠ›æµ‹è¯• - {gpu_name}")
        print(f"{'='*70}")
        print(f"  ç†è®ºå³°å€¼: {peak_tflops} TFLOPS ({self.dtype})")
        print(f"  æµ‹è¯•ç‚¹æ•°: {len(test_points)}")
        print(f"  é¢„çƒ­æ¬¡æ•°: {warmup_iters}, åŸºå‡†æ¬¡æ•°: {bench_iters}")
        print(f"{'-'*70}")
        print(f"{'M':>8} {'N':>8} {'K':>8} {'Time(ms)':>12} {'TFLOPS':>10} {'Efficiency':>12}")
        print(f"{'-'*70}")
        
        results = []
        
        for m, n, k in test_points:
            try:
                point = self.run_gemm_test(m, n, k, warmup_iters, bench_iters)
                point.efficiency = point.tflops / peak_tflops
                
                results.append(asdict(point))
                
                print(f"{m:>8} {n:>8} {k:>8} {point.time_ms:>12.3f} "
                      f"{point.tflops:>10.2f} {point.efficiency:>11.1%}")
                
            except Exception as e:
                print(f"{m:>8} {n:>8} {k:>8} {'FAILED':>12} - {e}")
        
        print(f"{'-'*70}")
        
        # åˆ›å»º Profile
        profile = ComputeProfile(
            gpu_name=gpu_name,
            gpu_count=gpu_count,
            peak_tflops=peak_tflops,
            test_date=datetime.now().strftime("%Y-%m-%d_%H-%M-%S"),
            dtype=self.dtype,
            gemm_results=results,
        )
        
        # æ‹Ÿåˆæ•ˆç‡æ›²çº¿
        self._fit_efficiency_curve(profile)
        
        self.profile = profile
        
        # æ‰“å°æ‹Ÿåˆç»“æœ
        print(f"\nğŸ“Š æ•ˆç‡æ‹Ÿåˆç»“æœ:")
        print(f"  å°è§„æ¨¡ (< 1e9 FLOPs):    {profile.efficiency_small:.1%}")
        print(f"  ä¸­ç­‰è§„æ¨¡ (1e9 - 1e11):   {profile.efficiency_medium:.1%}")
        print(f"  å¤§è§„æ¨¡ (>= 1e11):        {profile.efficiency_large:.1%}")
        print(f"  å¯¹æ•°æ‹Ÿåˆ: efficiency = {profile.fit_a:.4f} * log10(FLOPs) + {profile.fit_b:.4f}")
        print(f"{'='*70}\n")
        
        return profile
    
    def _fit_efficiency_curve(self, profile: ComputeProfile):
        """
        æ‹Ÿåˆæ•ˆç‡æ›²çº¿
        
        ä½¿ç”¨ä¸¤ç§æ–¹å¼ï¼š
        1. åˆ†æ®µå¹³å‡æ•ˆç‡
        2. å¯¹æ•°çº¿æ€§æ‹Ÿåˆ: efficiency = a * log10(FLOPs) + b
        """
        if not profile.gemm_results:
            return
        
        # åˆ†ç±»æ•°æ®ç‚¹
        small_effs = []
        medium_effs = []
        large_effs = []
        
        log_flops_list = []
        efficiency_list = []
        
        for result in profile.gemm_results:
            flops = 2 * result["m"] * result["n"] * result["k"]
            eff = result["efficiency"]
            
            log_flops_list.append(np.log10(flops))
            efficiency_list.append(eff)
            
            if flops < 1e9:
                small_effs.append(eff)
            elif flops < 1e11:
                medium_effs.append(eff)
            else:
                large_effs.append(eff)
        
        # åˆ†æ®µå¹³å‡æ•ˆç‡
        profile.efficiency_small = np.mean(small_effs) if small_effs else 0.3
        profile.efficiency_medium = np.mean(medium_effs) if medium_effs else 0.5
        profile.efficiency_large = np.mean(large_effs) if large_effs else 0.6
        
        # å¯¹æ•°çº¿æ€§æ‹Ÿåˆ
        if len(log_flops_list) >= 2:
            log_flops = np.array(log_flops_list)
            efficiencies = np.array(efficiency_list)
            
            # ç®€å•çº¿æ€§å›å½’: y = ax + b
            n = len(log_flops)
            sum_x = np.sum(log_flops)
            sum_y = np.sum(efficiencies)
            sum_xy = np.sum(log_flops * efficiencies)
            sum_xx = np.sum(log_flops * log_flops)
            
            denom = n * sum_xx - sum_x * sum_x
            if abs(denom) > 1e-10:
                profile.fit_a = (n * sum_xy - sum_x * sum_y) / denom
                profile.fit_b = (sum_y - profile.fit_a * sum_x) / n
    
    def estimate_training_efficiency(self, 
                                     hidden_size: int = 6144,
                                     intermediate_size: int = 16384,
                                     seq_len: int = 8192,
                                     batch_size: int = 1,
                                     num_samples: int = 10) -> float:
        """
        ä¼°ç®—çœŸå®è®­ç»ƒåœºæ™¯çš„å¹³å‡æ•ˆç‡
        
        éšæœºé‡‡æ ·è®­ç»ƒä¸­å¯èƒ½å‡ºç°çš„ GEMM è§„æ¨¡ï¼Œè®¡ç®—å¹³å‡æ•ˆç‡
        """
        if self.profile is None:
            return 0.5  # é»˜è®¤å€¼
        
        # å…¸å‹çš„ Transformer GEMM è§„æ¨¡
        gemm_types = [
            # Attention: QKV projection
            (batch_size * seq_len, hidden_size * 3, hidden_size),
            # Attention: Output projection
            (batch_size * seq_len, hidden_size, hidden_size),
            # MLP: Gate and Up
            (batch_size * seq_len, intermediate_size * 2, hidden_size),
            # MLP: Down
            (batch_size * seq_len, hidden_size, intermediate_size),
        ]
        
        efficiencies = []
        for m, n, k in gemm_types:
            eff = self.profile.get_efficiency(m, n, k)
            efficiencies.append(eff)
        
        return np.mean(efficiencies)
    
    def save_profile(self, save_dir: str = "./profiles") -> str:
        """
        ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶
        
        æ–‡ä»¶åæ ¼å¼: {gpu_name}_{date}.json
        
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if self.profile is None:
            raise ValueError("No profile to save. Run run_full_profile() first.")
        
        os.makedirs(save_dir, exist_ok=True)
        
        # æ¸…ç† GPU åç§°ç”¨äºæ–‡ä»¶å
        gpu_name_clean = self.profile.gpu_name.replace(" ", "_").replace("/", "-")
        filename = f"{gpu_name_clean}_{self.profile.test_date}.json"
        filepath = os.path.join(save_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.profile.to_dict(), f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Profile å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    
    def load_profile(self, filepath: str) -> ComputeProfile:
        """ä»æ–‡ä»¶åŠ è½½æµ‹è¯•ç»“æœ"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.profile = ComputeProfile.from_dict(data)
        print(f"âœ… å·²åŠ è½½ Profile: {self.profile.gpu_name} ({self.profile.test_date})")
        return self.profile
    
    @staticmethod
    def list_profiles(save_dir: str = "./profiles") -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„ Profile æ–‡ä»¶"""
        if not os.path.exists(save_dir):
            return []
        
        files = [f for f in os.listdir(save_dir) if f.endswith('.json')]
        return sorted(files)


# ==================== ä¾¿æ·å‡½æ•° ====================

def profile_and_save(peak_tflops: float = 989.0,
                     dtype: str = "bfloat16",
                     save_dir: str = "./profiles") -> str:
    """
    è¿è¡Œç®—åŠ›æµ‹è¯•å¹¶ä¿å­˜ç»“æœ
    
    Args:
        peak_tflops: GPU ç†è®ºå³°å€¼ç®—åŠ›
        dtype: æ•°æ®ç±»å‹
        save_dir: ä¿å­˜ç›®å½•
    
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    profiler = ComputeProfiler(dtype=dtype)
    profiler.run_full_profile(peak_tflops=peak_tflops)
    return profiler.save_profile(save_dir)


def load_latest_profile(save_dir: str = "./profiles") -> Optional[ComputeProfile]:
    """åŠ è½½æœ€æ–°çš„ Profile æ–‡ä»¶"""
    profiler = ComputeProfiler()
    files = profiler.list_profiles(save_dir)
    
    if not files:
        print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ° Profile æ–‡ä»¶åœ¨ {save_dir}")
        return None
    
    latest_file = files[-1]  # æ–‡ä»¶ååŒ…å«æ—¥æœŸï¼Œæ’åºåæœ€åä¸€ä¸ªæ˜¯æœ€æ–°çš„
    filepath = os.path.join(save_dir, latest_file)
    
    return profiler.load_profile(filepath)


# ==================== æµ‹è¯•å‡½æ•° ====================

def test_compute_profiler():
    """æµ‹è¯•ç®—åŠ› Profiler"""
    print("=" * 70)
    print("æµ‹è¯• ComputeProfiler")
    print("=" * 70)
    
    # åˆ›å»º Profiler
    profiler = ComputeProfiler(dtype="bfloat16")
    
    # è¿è¡Œæµ‹è¯•ï¼ˆä½¿ç”¨è¾ƒå°‘çš„æµ‹è¯•ç‚¹åŠ å¿«é€Ÿåº¦ï¼‰
    test_points = [
        (1024, 6144, 6144),
        (4096, 6144, 16384),
        (8192, 16384, 6144),
    ]
    
    profile = profiler.run_full_profile(
        test_points=test_points,
        warmup_iters=5,
        bench_iters=20,
        peak_tflops=989.0
    )
    
    # æµ‹è¯•æ•ˆç‡ä¼°ç®—
    print("\nğŸ“Š è®­ç»ƒæ•ˆç‡ä¼°ç®—:")
    for seq_len in [1024, 2048, 4096, 8192]:
        eff = profiler.estimate_training_efficiency(
            hidden_size=6144,
            intermediate_size=16384,
            seq_len=seq_len,
            batch_size=1
        )
        print(f"  seq_len={seq_len}: å¹³å‡æ•ˆç‡ {eff:.1%}")
    
    # ä¿å­˜
    filepath = profiler.save_profile("./profiles")
    
    # é‡æ–°åŠ è½½
    profiler2 = ComputeProfiler()
    profiler2.load_profile(filepath)
    
    print("\næµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    test_compute_profiler()